# üéì UIT Voice Assistant

An AI-powered **voice assistant** for UIT (University Institute of Technology) that works like Google Assistant ‚Äî always listening for a wake word, answers questions using a custom knowledge base, and leverages **Ollama (llama3.2)** for versatile local AI responses.

---

## ‚ú® Features

| Feature | Description |
|---|---|
| **Wake Word Activation** | Say **"Hey Assistant"**, **"Hey Computer"**, or **"OK Assistant"** to activate |
| **Custom Knowledge Base** | Answers college-specific questions from `UIT Data Set.docx` and web sources |
| **Local LLM (Ollama)** | Uses Ollama with llama3.2 for private, offline AI responses |
| **Hybrid RAG Pipeline** | Automatically routes queries ‚Äî college data via RAG, everything else via Ollama |
| **System Tray App** | Runs silently in the background with a tray icon (like Cortana/Google Assistant) |
| **Offline TTS** | Speaks responses aloud using `pyttsx3` (no internet needed for speech output) |
| **Console Mode** | Text-based mode for testing without a microphone |
| **Raspberry Pi 4** | Runs as an always-on systemd service ‚Äî auto-starts on boot |

---

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   System Tray App                    ‚îÇ
‚îÇ              (tray_app.py / main.py)                 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ Wake Word‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Speech-to-   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Hybrid   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ Detector ‚îÇ    ‚îÇ Text (STT)   ‚îÇ    ‚îÇ Pipeline ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                           ‚îÇ         ‚îÇ
‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§         ‚îÇ
‚îÇ                    ‚ñº                      ‚ñº         ‚îÇ
‚îÇ             ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ             ‚îÇ RAG +    ‚îÇ          ‚îÇ  Ollama  ‚îÇ     ‚îÇ
‚îÇ             ‚îÇ ChromaDB ‚îÇ          ‚îÇ (General)‚îÇ     ‚îÇ
‚îÇ             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îÇ                    ‚îÇ                      ‚îÇ         ‚îÇ
‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îÇ                               ‚ñº                     ‚îÇ
‚îÇ                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ
‚îÇ                      ‚îÇ Text-to-     ‚îÇ               ‚îÇ
‚îÇ                      ‚îÇ Speech (TTS) ‚îÇ               ‚îÇ
‚îÇ                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ
‚îÇ                                                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìÇ Project Structure

```
cllg_chatbot/
‚îú‚îÄ‚îÄ main.py                    # Main entry point
‚îú‚îÄ‚îÄ assistant.py               # Core voice assistant logic
‚îú‚îÄ‚îÄ tray_app.py                # System tray application (Windows)
‚îú‚îÄ‚îÄ config.py                  # Central configuration (auto-detects Pi)
‚îú‚îÄ‚îÄ UIT Data Set.docx          # Primary knowledge base ‚≠ê
‚îÇ
‚îú‚îÄ‚îÄ pi/                        # Raspberry Pi 4 files
‚îÇ   ‚îú‚îÄ‚îÄ install_pi.sh          # One-command full Pi setup
‚îÇ   ‚îú‚îÄ‚îÄ uit-assistant.service  # systemd service (auto-start on boot)
‚îÇ   ‚îú‚îÄ‚îÄ ollama.service         # Ollama systemd service
‚îÇ   ‚îú‚îÄ‚îÄ asoundrc               # ALSA audio config for USB mic
‚îÇ   ‚îî‚îÄ‚îÄ test_audio.sh          # Test speaker & mic on Pi
‚îÇ
‚îú‚îÄ‚îÄ voice/                     # Voice I/O modules
‚îÇ   ‚îú‚îÄ‚îÄ speech_to_text.py      # Microphone ‚Üí text
‚îÇ   ‚îú‚îÄ‚îÄ text_to_speech.py      # Text ‚Üí speech
‚îÇ   ‚îî‚îÄ‚îÄ wake_word.py           # Wake word detection
‚îÇ
‚îú‚îÄ‚îÄ rag/                       # AI pipeline
‚îÇ   ‚îî‚îÄ‚îÄ hybrid_pipeline.py     # RAG + Ollama router
‚îÇ
‚îú‚îÄ‚îÄ llm/                       # LLM clients
‚îÇ   ‚îî‚îÄ‚îÄ ollama_client.py       # Local Ollama (llama3.2)
‚îÇ
‚îú‚îÄ‚îÄ ingestion/                 # Data processing
‚îÇ   ‚îú‚îÄ‚îÄ run_ingestion.py       # Full pipeline
‚îÇ   ‚îú‚îÄ‚îÄ pdf_ingestor.py        # PDF/DOCX/TXT reader
‚îÇ   ‚îú‚îÄ‚îÄ web_ingestor.py        # Web scraper
‚îÇ   ‚îú‚îÄ‚îÄ normalizer.py          # Text cleanup
‚îÇ   ‚îú‚îÄ‚îÄ chunker.py             # Text chunking
‚îÇ   ‚îî‚îÄ‚îÄ embedder.py            # Sentence embeddings
‚îÇ
‚îú‚îÄ‚îÄ vector_db/                 # Vector store
‚îÇ   ‚îú‚îÄ‚îÄ chroma_client.py       # ChromaDB client
‚îÇ   ‚îú‚îÄ‚îÄ indexer.py             # Chunk indexer
‚îÇ   ‚îî‚îÄ‚îÄ retriever.py           # Similarity search
‚îÇ
‚îî‚îÄ‚îÄ data/                      # Processed data
    ‚îú‚îÄ‚îÄ raw_pdfs/
    ‚îú‚îÄ‚îÄ extracted_text/
    ‚îú‚îÄ‚îÄ normalized_text/
    ‚îî‚îÄ‚îÄ processed_chunks/
```

---

## üöÄ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

> **Note:** On Windows, `PyAudio` may need a pre-built wheel:
> ```bash
> pip install pipwin
> pipwin install pyaudio
> ```

### 2. Install & Start Ollama

Download from [ollama.com](https://ollama.com/) and pull the model:

```bash
ollama pull llama3.2
ollama serve    # keep running in background
```

### 3. Ingest Knowledge Base

Process `UIT Data Set.docx` and web sources into the vector database:

```bash
python main.py --ingest
```

### 4. Start the Assistant

```bash
# System tray mode (recommended ‚Äî runs in background)
python main.py

# Voice-only mode (no tray icon)
python main.py --voice

# Console/text mode (for testing without microphone)
python main.py --console
```

---

## üé§ Usage

1. **Start the app** ‚Äî it runs in the system tray
2. **Say "Hey Assistant"** ‚Äî the assistant activates
3. **Ask your question** ‚Äî speak naturally
4. **Listen to the response** ‚Äî the assistant speaks the answer
5. **Follow-up** ‚Äî keep asking or stay silent to deactivate

### Example Queries

- *"What programs does UIT offer?"* ‚Üí Answered from knowledge base
- *"What is the code of conduct?"* ‚Üí Answered from knowledge base
- *"Tell me about the library"* ‚Üí Answered from knowledge base
- *"What is quantum computing?"* ‚Üí Answered by Ollama
- *"Write me a poem about college"* ‚Üí Answered by Ollama
- *"What time is it?"* ‚Üí Handled by system

---

## ‚öôÔ∏è Configuration

Edit `config.py` to customize:

| Setting | Default | Description |
|---|---|---|
| `WAKE_WORDS` | `["hey assistant", "hey computer", "ok assistant"]` | Trigger phrases |
| `OLLAMA_MODEL` | `llama3.2` | Ollama model to use |
| `TOP_K` | `5` | Number of RAG chunks to retrieve |
| `TTS_RATE` | `175` | Speech speed (words/min) |
| `CHUNK_SIZE` | `500` | Words per chunk |

---

## üìã Requirements

- Python 3.10+
- Microphone (for voice mode)
- [Ollama](https://ollama.com/) installed and running
- Internet connection (for Google STT ‚Äî optional if using offline STT)

---

## üçì Raspberry Pi 4 Deployment

The assistant is fully compatible with **Raspberry Pi 4 (4GB+ RAM, 64-bit OS)** and runs as an always-on system service ‚Äî just like a smart speaker.

### Hardware Needed

| Item | Notes |
|---|---|
| Raspberry Pi 4 (4GB+) | 8GB recommended for best LLM performance |
| USB Microphone | Any USB mic (e.g., ReSpeaker, Blue Snowball) |
| Speaker / Headphones | 3.5mm jack or USB speaker |
| MicroSD Card (32GB+) | With Raspberry Pi OS 64-bit |
| Power supply | Official Pi 4 USB-C adapter |

### One-Command Install

```bash
# 1. Copy project to your Pi (via SCP, USB, or git clone)
cd /home/pi
git clone <your-repo-url> cllg_chatbot  # or copy the folder

# 2. Run the installer (does everything automatically)
cd cllg_chatbot
chmod +x pi/install_pi.sh
sudo ./pi/install_pi.sh
```

This single script will:
1. Install all system packages (Python, PortAudio, espeak, ALSA)
2. Configure audio (USB mic + headphone jack)
3. Install Ollama and pull the llama3.2 model
4. Set up Python virtual environment and install dependencies
5. Ingest the UIT knowledge base
6. Install and start **systemd services** for both Ollama and the assistant
7. Enable auto-start on every boot

### After Installation

The assistant **starts automatically** on boot. Just say **"Hey Assistant"**!

```bash
# Check status
sudo systemctl status uit-assistant

# View live logs
journalctl -u uit-assistant -f

# Restart
sudo systemctl restart uit-assistant

# Stop
sudo systemctl stop uit-assistant

# Disable auto-start
sudo systemctl disable uit-assistant
```

### Test Audio on Pi

Before running, verify your mic and speaker work:

```bash
chmod +x pi/test_audio.sh
./pi/test_audio.sh
```

### Pi-Specific Notes

- **Audio**: Default config uses USB mic for input and 3.5mm jack for output. Edit `pi/asoundrc` if your setup differs. Run `arecord -l` to find your mic's card number.
- **Model**: llama3.2 (3B) runs on Pi 4 with 4GB RAM. For faster responses, consider `tinyllama` or `phi`.
- **Memory**: Close other apps. The LLM + embeddings use most of the RAM.
- **First boot**: The first query takes longer as models load into memory. Subsequent queries are faster.